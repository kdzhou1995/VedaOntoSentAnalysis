{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "from lexical_sources.scherers_categories_stems import abbreviations\n",
    "\n",
    "from wordsegment import load\n",
    "import csv\n",
    "\n",
    "from autocorrect import Speller\n",
    "import csv\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load() # load words for word segment\n",
    "\n",
    "spellChecker = Speller(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "skip = True\n",
    "\n",
    "if not skip:\n",
    "    data = open(Config.raw_data_path, \"r\", encoding=\"utf8\")\n",
    "\n",
    "\n",
    "    next(data)\n",
    "    no_line = 0\n",
    "\n",
    "    outfile = open(\"misspelledwords.txt\",'w')\n",
    "    ##outfile1 = open(\"sentences\")\n",
    "    dct = {}\n",
    "\n",
    "    for tweet_data in csv.reader(data):\n",
    "        ##if no_line == 1:\n",
    "        ##    break\n",
    "        \n",
    "        id, raw_tweet, label = tweet_data[0], tweet_data[1], tweet_data[2]\n",
    "\n",
    "        # parse into sentences on punctuation marks\n",
    "\n",
    "        sentences = re.split(r\"[!?.]\", raw_tweet)\n",
    "\n",
    "        for sentence in sentences[:10]:\n",
    "            sentence = sentence.replace('\\n',' ').translate(str.maketrans('', '', \"*\"))\n",
    "            for word in sentence.split():       \n",
    "                word = word.lower().strip()\n",
    "                if word != spellChecker(word):\n",
    "                    if word not in dct:\n",
    "                        corrected_word = spellChecker(word)\n",
    "                        dct[word] = corrected_word\n",
    "                        print(f\"{id}|{word}|{corrected_word}|{sentence.strip()}\")\n",
    "                        outfile.write(f\"{id}|{word}|{corrected_word}|{sentence}|\\n\")\n",
    "\n",
    "        ##no_line += 1\n",
    "\n",
    "    outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    scherer_file = open(f\"{Config.lexical_sources}/ScherersCategories&Stems.csv\",\"r\", encoding=\"utf-8\")\n",
    "    file_reader = csv.reader(scherer_file)\n",
    "\n",
    "    for line in file_reader:\n",
    "        category = line[0].strip()\n",
    "        stems = [x for x in line[1:] if \"*\" in x ]\n",
    "        words = [x for x in line[1:] if \"*\" not in x and x != \"\" ]\n",
    "\n",
    "        print(f\"'{category}' : \" + \"{\\n\\t\\t\\t\\t\\t'stems': \" + f\"{stems}\" + \",\")\n",
    "        print(\"\\t\\t\\t\\t\\t'words': \" + f\"{words}\" + \"\\n},\")\n",
    "    scherer_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
